{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a25b897",
   "metadata": {},
   "source": [
    "# 01: Data Exploration\n",
    "\n",
    "This notebook explores the ThickBloodSmears_150 dataset, visualizes class distribution,\n",
    "examines sample images, and analyzes image properties to understand the dataset characteristics.\n",
    "\n",
    "## Objectives\n",
    "1. Load and explore dataset structure\n",
    "2. Visualize class distribution\n",
    "3. Display sample infected and uninfected slides\n",
    "4. Analyze image properties (resolution, color distribution)\n",
    "5. Check for data quality issues\n",
    "6. Assess preprocessing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dd586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Import from project\n",
    "from src.data.dataset_loader import ThickBloodSmearsLoader\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854caca7",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset loader\n",
    "print(\"Loading ThickBloodSmears_150 dataset...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define dataset path - update this to match your local dataset location\n",
    "dataset_path = Path(\"../data/raw/ThickBloodSmears_150\")  # Adjust as needed\n",
    "\n",
    "# Check if dataset exists\n",
    "if not dataset_path.exists():\n",
    "    print(f\"‚ö†Ô∏è  Dataset not found at {dataset_path}\")\n",
    "    print(\"Please download the ThickBloodSmears_150 dataset and place it at the path above\")\n",
    "    dataset_path = None\n",
    "else:\n",
    "    loader = ThickBloodSmearsLoader(\n",
    "        data_dir=str(dataset_path),\n",
    "        image_size=224\n",
    "    )\n",
    "    print(f\"‚úì Dataset loaded from {dataset_path}\")\n",
    "    print(f\"Total images: {len(loader.image_files)}\")\n",
    "    print(f\"Classes: {loader.class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b40a78",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path and dataset_path.exists():\n",
    "    # Count images per class\n",
    "    class_counts = Counter()\n",
    "    for label in loader.labels:\n",
    "        class_counts[label] += 1\n",
    "    \n",
    "    print(\"Class Distribution:\")\n",
    "    print(\"=\"*40)\n",
    "    for class_idx, class_name in enumerate(loader.class_names):\n",
    "        count = class_counts.get(class_idx, 0)\n",
    "        percentage = (count / len(loader.labels)) * 100\n",
    "        bar = \"‚ñà\" * int(percentage / 5)\n",
    "        print(f\"{class_name:15} | {count:3d} images ({percentage:5.1f}%) {bar}\")\n",
    "    \n",
    "    # Visualize class distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar plot\n",
    "    classes = [loader.class_names[i] for i in range(len(loader.class_names))]\n",
    "    counts = [class_counts.get(i, 0) for i in range(len(loader.class_names))]\n",
    "    colors = ['#2ecc71', '#e74c3c']  # Green for uninfected, red for infected\n",
    "    \n",
    "    axes[0].bar(classes, counts, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    axes[0].set_ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (class_name, count) in enumerate(zip(classes, counts)):\n",
    "        axes[0].text(i, count + 1, str(count), ha='center', fontweight='bold')\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(counts, labels=classes, colors=colors, autopct='%1.1f%%',\n",
    "                startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "    axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate imbalance ratio\n",
    "    class_ratios = {loader.class_names[i]: counts[i] for i in range(len(loader.class_names))}\n",
    "    max_count = max(counts)\n",
    "    imbalance_ratio = max_count / min(counts) if min(counts) > 0 else float('inf')\n",
    "    \n",
    "    print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    if imbalance_ratio > 1.5:\n",
    "        print(\"‚ö†Ô∏è  Significant class imbalance detected - weighted loss and stratified splitting recommended\")\n",
    "    else:\n",
    "        print(\"‚úì Classes are relatively balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103379e",
   "metadata": {},
   "source": [
    "## 3. Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12667634",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path and dataset_path.exists():\n",
    "    # Get sample indices for each class\n",
    "    samples_per_class = 3\n",
    "    class_indices = {i: [] for i in range(len(loader.class_names))}\n",
    "    \n",
    "    for idx, label in enumerate(loader.labels):\n",
    "        if len(class_indices[label]) < samples_per_class:\n",
    "            class_indices[label].append(idx)\n",
    "    \n",
    "    # Display samples\n",
    "    fig, axes = plt.subplots(len(loader.class_names), samples_per_class,\n",
    "                             figsize=(15, 8))\n",
    "    \n",
    "    for class_idx, class_name in enumerate(loader.class_names):\n",
    "        for sample_idx, img_idx in enumerate(class_indices[class_idx]):\n",
    "            image_path = loader.image_files[img_idx]\n",
    "            img = cv2.imread(str(image_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            ax = axes[class_idx, sample_idx]\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{class_name}\\n({image_path.name})\", fontsize=10, fontweight='bold')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images by Class', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úì Sample images displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cac124",
   "metadata": {},
   "source": [
    "## 4. Image Properties Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path and dataset_path.exists():\n",
    "    print(\"Analyzing image properties...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    image_properties = {\n",
    "        'heights': [],\n",
    "        'widths': [],\n",
    "        'channels': [],\n",
    "        'file_sizes': [],\n",
    "        'formats': []\n",
    "    }\n",
    "    \n",
    "    for image_path in loader.image_files:\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is not None:\n",
    "            h, w, c = img.shape\n",
    "            image_properties['heights'].append(h)\n",
    "            image_properties['widths'].append(w)\n",
    "            image_properties['channels'].append(c)\n",
    "            \n",
    "            file_size = os.path.getsize(image_path) / 1024  # in KB\n",
    "            image_properties['file_sizes'].append(file_size)\n",
    "            \n",
    "            fmt = image_path.suffix.lower()\n",
    "            image_properties['formats'].append(fmt)\n",
    "    \n",
    "    # Statistics\n",
    "    print(\"\\nImage Dimensions:\")\n",
    "    print(f\"  Height: {np.mean(image_properties['heights']):.1f} ¬± {np.std(image_properties['heights']):.1f}\")\n",
    "    print(f\"          (min: {np.min(image_properties['heights'])}, max: {np.max(image_properties['heights'])})\")\n",
    "    print(f\"  Width:  {np.mean(image_properties['widths']):.1f} ¬± {np.std(image_properties['widths']):.1f}\")\n",
    "    print(f\"          (min: {np.min(image_properties['widths'])}, max: {np.max(image_properties['widths'])})\")\n",
    "    \n",
    "    print(f\"\\nImage Channels: {Counter(image_properties['channels'])}\")\n",
    "    \n",
    "    print(f\"\\nFile Sizes:\")\n",
    "    print(f\"  Mean: {np.mean(image_properties['file_sizes']):.1f} KB\")\n",
    "    print(f\"  Range: {np.min(image_properties['file_sizes']):.1f} - {np.max(image_properties['file_sizes']):.1f} KB\")\n",
    "    \n",
    "    print(f\"\\nImage Formats: {Counter(image_properties['formats'])}\")\n",
    "    \n",
    "    # Visualize dimensions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    axes[0, 0].hist(image_properties['heights'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Height (pixels)', fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Count', fontweight='bold')\n",
    "    axes[0, 0].set_title('Image Height Distribution', fontweight='bold')\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].hist(image_properties['widths'], bins=20, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Width (pixels)', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Count', fontweight='bold')\n",
    "    axes[0, 1].set_title('Image Width Distribution', fontweight='bold')\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].hist(image_properties['file_sizes'], bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('File Size (KB)', fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Count', fontweight='bold')\n",
    "    axes[1, 0].set_title('File Size Distribution', fontweight='bold')\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    formats_count = Counter(image_properties['formats'])\n",
    "    axes[1, 1].bar(formats_count.keys(), formats_count.values(),\n",
    "                   color='plum', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('File Format', fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Count', fontweight='bold')\n",
    "    axes[1, 1].set_title('Image Format Distribution', fontweight='bold')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd3873",
   "metadata": {},
   "source": [
    "## 5. Color Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path and dataset_path.exists():\n",
    "    print(\"Analyzing color distribution (Giemsa staining patterns)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Analyze color channels for each class\n",
    "    color_stats = {}\n",
    "    for class_idx, class_name in enumerate(loader.class_names):\n",
    "        class_mask = np.array(loader.labels) == class_idx\n",
    "        class_indices = np.where(class_mask)[0][:5]  # First 5 images of class\n",
    "        \n",
    "        r_values, g_values, b_values = [], [], []\n",
    "        \n",
    "        for idx in class_indices:\n",
    "            image_path = loader.image_files[idx]\n",
    "            img = cv2.imread(str(image_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            r_values.extend(img_rgb[:,:,0].flatten())\n",
    "            g_values.extend(img_rgb[:,:,1].flatten())\n",
    "            b_values.extend(img_rgb[:,:,2].flatten())\n",
    "        \n",
    "        color_stats[class_name] = {\n",
    "            'R': np.mean(r_values),\n",
    "            'G': np.mean(g_values),\n",
    "            'B': np.mean(b_values)\n",
    "        }\n",
    "    \n",
    "    # Display color statistics\n",
    "    print(\"\\nMean Color Values (RGB):\")\n",
    "    for class_name, rgb in color_stats.items():\n",
    "        print(f\"  {class_name:15}: R={rgb['R']:.1f}, G={rgb['G']:.1f}, B={rgb['B']:.1f}\")\n",
    "    \n",
    "    # Visualize color distributions\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    channels = ['R', 'G', 'B']\n",
    "    \n",
    "    for i, channel in enumerate(channels):\n",
    "        for class_name, rgb in color_stats.items():\n",
    "            axes[i].bar(class_name, rgb[channel], alpha=0.7, label=class_name)\n",
    "        \n",
    "        axes[i].set_ylabel(f'{channel} Channel Intensity', fontweight='bold')\n",
    "        axes[i].set_title(f'{channel} Channel Distribution', fontweight='bold')\n",
    "        axes[i].set_ylim([0, 255])\n",
    "        axes[i].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìå Giemsa staining produces characteristic colors:\")\n",
    "    print(\"  - RBCs: Pale/transparent\")\n",
    "    print(\"  - Parasites: Deep blue/purple nucleus, pink/red cytoplasm\")\n",
    "    print(\"  - WBCs: Blue nucleus, light blue cytoplasm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f887a80",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path and dataset_path.exists():\n",
    "    print(\"Data Quality Assessment\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    quality_issues = []\n",
    "    \n",
    "    # Check for corrupted images\n",
    "    corrupted_count = 0\n",
    "    for image_path in loader.image_files:\n",
    "        try:\n",
    "            img = cv2.imread(str(image_path))\n",
    "            if img is None:\n",
    "                corrupted_count += 1\n",
    "                quality_issues.append(f\"Corrupted: {image_path.name}\")\n",
    "        except:\n",
    "            corrupted_count += 1\n",
    "            quality_issues.append(f\"Error reading: {image_path.name}\")\n",
    "    \n",
    "    print(f\"Corrupted images: {corrupted_count}/{len(loader.image_files)}\")\n",
    "    if corrupted_count == 0:\n",
    "        print(\"‚úì All images readable\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {corrupted_count} corrupted images found\")\n",
    "    \n",
    "    # Check for extreme image sizes\n",
    "    heights = image_properties['heights']\n",
    "    widths = image_properties['widths']\n",
    "    aspect_ratios = [h/w for h, w in zip(heights, widths)]\n",
    "    \n",
    "    print(f\"\\nImage size consistency:\")\n",
    "    if np.std(heights) > np.mean(heights) * 0.1:\n",
    "        print(\"‚ö†Ô∏è  Heights vary significantly (need resizing)\")\n",
    "    else:\n",
    "        print(\"‚úì Heights relatively consistent\")\n",
    "    \n",
    "    if np.std(widths) > np.mean(widths) * 0.1:\n",
    "        print(\"‚ö†Ô∏è  Widths vary significantly (need resizing)\")\n",
    "    else:\n",
    "        print(\"‚úì Widths relatively consistent\")\n",
    "    \n",
    "    print(f\"\\nAspect ratio range: {np.min(aspect_ratios):.2f} - {np.max(aspect_ratios):.2f}\")\n",
    "    if np.std(aspect_ratios) < 0.1:\n",
    "        print(\"‚úì Aspect ratios consistent (mostly square)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Variable aspect ratios detected\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA QUALITY SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(quality_issues) == 0:\n",
    "        print(\"‚úì Overall data quality: GOOD\")\n",
    "        print(\"  - No corrupted images\")\n",
    "        print(\"  - Consistent dimensions\")\n",
    "        print(\"  - Ready for preprocessing\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Issues detected: {len(quality_issues)}\")\n",
    "        for issue in quality_issues[:5]:\n",
    "            print(f\"  - {issue}\")\n",
    "        if len(quality_issues) > 5:\n",
    "            print(f\"  ... and {len(quality_issues) - 5} more issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3592ab8",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_path and dataset_path.exists():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATASET SUMMARY & PREPROCESSING RECOMMENDATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Recommendation 1: Image resizing\n",
    "    print(f\"\\n1. IMAGE RESIZING\")\n",
    "    print(f\"   Current size: variable\")\n",
    "    print(f\"   Recommended: 224√ó224 pixels\")\n",
    "    print(f\"   Reason: Standard input for transfer learning models\")\n",
    "    recommendations.append(\"Resize all images to 224√ó224\")\n",
    "    \n",
    "    # Recommendation 2: Class imbalance\n",
    "    print(f\"\\n2. CLASS IMBALANCE HANDLING\")\n",
    "    if imbalance_ratio > 1.5:\n",
    "        print(f\"   Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "        print(f\"   Recommended: Weighted loss functions\")\n",
    "        print(f\"   Also: Stratified train/val/test split\")\n",
    "        recommendations.append(\"Use weighted BCE or focal loss\")\n",
    "        recommendations.append(\"Implement stratified splitting (70/15/15)\")\n",
    "    else:\n",
    "        print(f\"   Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "        print(f\"   Status: Relatively balanced\")\n",
    "    \n",
    "    # Recommendation 3: Augmentation\n",
    "    print(f\"\\n3. DATA AUGMENTATION\")\n",
    "    print(f\"   Dataset size: {len(loader.image_files)} images\")\n",
    "    print(f\"   Recommended: Medical-safe augmentation\")\n",
    "    print(f\"   - Rotation: 0-360¬∞\")\n",
    "    print(f\"   - Flips: Horizontal & vertical\")\n",
    "    print(f\"   - Brightness/Contrast: ¬±20%\")\n",
    "    print(f\"   - Elastic deformations: moderate\")\n",
    "    recommendations.append(\"Apply medical-safe augmentation (rotation, flips, brightness)\")\n",
    "    \n",
    "    # Recommendation 4: Preprocessing\n",
    "    print(f\"\\n4. MICROSCOPY-SPECIFIC PREPROCESSING\")\n",
    "    print(f\"   Step 1: CLAHE (Contrast Limited Adaptive Histogram)\")\n",
    "    print(f\"   Step 2: Color normalization (handle staining variations)\")\n",
    "    print(f\"   Step 3: Pixel normalization (ImageNet standard)\")\n",
    "    recommendations.append(\"Apply CLAHE for contrast enhancement\")\n",
    "    recommendations.append(\"Normalize color (Giemsa staining variation)\")\n",
    "    \n",
    "    # Recommendation 5: Model selection\n",
    "    print(f\"\\n5. MODEL ARCHITECTURE\")\n",
    "    print(f\"   Small dataset ({len(loader.image_files)} images) with medical focus\")\n",
    "    print(f\"   Recommended:\")\n",
    "    print(f\"   - Transfer Learning (ResNet50, DenseNet121) - PRIMARY\")\n",
    "    print(f\"   - Medical CNN with attention mechanism - SECONDARY\")\n",
    "    print(f\"   - Ensemble of multiple models - OPTIMAL\")\n",
    "    recommendations.append(\"Use transfer learning with pre-trained weights\")\n",
    "    recommendations.append(\"Consider ensemble of 3-5 models for production\")\n",
    "    \n",
    "    # Recommendation 6: Validation strategy\n",
    "    print(f\"\\n6. VALIDATION & EVALUATION\")\n",
    "    print(f\"   Metric priority:\")\n",
    "    print(f\"   1. Sensitivity (Recall) - CRITICAL for screening\")\n",
    "    print(f\"   2. Specificity - Important for reducing false alarms\")\n",
    "    print(f\"   3. NPV (Negative Predictive Value) - Key for clinical trust\")\n",
    "    print(f\"   Split strategy: 70% train / 15% val / 15% test (stratified)\")\n",
    "    recommendations.append(\"Use stratified k-fold cross-validation\")\n",
    "    recommendations.append(\"Prioritize sensitivity in early stopping and model selection\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"NEXT STEPS:\")\n",
    "    print(f\"=\"*60)\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    \n",
    "    print(f\"\\nProceeding to: 02_image_preprocessing.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b591850",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úì Data exploration complete!\")\n",
    "print(\"\\nKey findings:\")\n",
    "print(f\"  ‚Ä¢ Total images: {len(loader.image_files) if dataset_path and dataset_path.exists() else 'N/A'}\")\n",
    "print(f\"  ‚Ä¢ Classes: Infected / Uninfected (binary classification)\")\n",
    "print(f\"  ‚Ä¢ Staining: Giemsa (thick blood smear)\")\n",
    "print(f\"  ‚Ä¢ Magnification: √ó1000 (oil immersion)\")\n",
    "print(f\"\\nReady for preprocessing in next notebook!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
